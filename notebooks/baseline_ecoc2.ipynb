{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['hamming', 'clf']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(132)\n",
    "from functools import lru_cache\n",
    "\n",
    "import sys\n",
    "\n",
    "CODE_PATH = '../code'\n",
    "\n",
    "sys.path.append(CODE_PATH)\n",
    "import functions\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_iris, load_boston, load_breast_cancer, load_wine, load_digits\n",
    "from scipy.optimize import minimize\n",
    "from tqdm import tqdm\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "бостон - градиент уходит в 0  \n",
    "ирис - спустя пару итераций в 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "[0 1 2 ... 8 9 8]\n"
     ]
    }
   ],
   "source": [
    "# dataset = load_breast_cancer()\n",
    "dataset = load_digits()\n",
    "df = pd.DataFrame(dataset['data'])\n",
    "target = dataset['target']\n",
    "# df = (df - df.mean())/(df.max() - df.min())\n",
    "# df0 = df.copy()\n",
    "print(df.shape)\n",
    "print(target)\n",
    "df.head()\n",
    "\n",
    "# train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.values, target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Формируем дихотомическую матрицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_classes\n",
    "l = np.unique(target).size\n",
    "N = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# формируем дих матрицу l*N\n",
    "code_matrix = np.zeros((l, N))\n",
    "def add_random_dich(l=10, code_matrix=None):\n",
    "    if code_matrix is None:\n",
    "        # матрица пуста\n",
    "        dich = np.random.randint(0, 2, l)\n",
    "        while np.unique(dich).size == 1:\n",
    "            dich = np.random.randint(0, 2, l)\n",
    "        return dich.reshape((-1, 1))\n",
    "    # матрица непуста\n",
    "    dich = np.random.randint(0, 2, l)\n",
    "    def does_dich_exist(dich, code_matrix):\n",
    "        diff = (cm == dich).sum(axis=0)\n",
    "        if diff.max() == l or diff.min() == 0:\n",
    "            return True\n",
    "        return False\n",
    "    while np.unique(dich).size == 1 and not does_dich_exist(dich, code_matrix):\n",
    "        dich = np.random.randint(0, 2, l)\n",
    "#     print(code_matrix.shape, dich.shape)\n",
    "    return np.hstack([code_matrix, dich.reshape((-1, 1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding dich: 100%|██████████| 25/25 [00:00<00:00, 17286.12it/s]\n"
     ]
    }
   ],
   "source": [
    "code_matrix = None\n",
    "for i in tqdm(range(N), desc='Adding dich'):\n",
    "    code_matrix = add_random_dich(l, code_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1],\n",
       "       [0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "        1, 0, 0],\n",
       "       [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "        0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "        1, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "        0, 0, 0],\n",
       "       [0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "        0, 0, 0],\n",
       "       [1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 0, 0],\n",
       "       [1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "        0, 1, 1],\n",
       "       [0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "        1, 0, 1],\n",
       "       [0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Поиск дихотомии через оптимум"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# начальная точка максимально удаленная от линейной оболочки дихотомий\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучаем классификаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training dich classifiers: 100%|██████████| 25/25 [00:00<00:00, 36.74it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "BaseClassifier = LogisticRegression\n",
    "dich_classifiers = []\n",
    "for i in tqdm(range(N), desc='Training dich classifiers'):\n",
    "    clf = BaseClassifier()\n",
    "    X = X_train\n",
    "    y_classes = code_matrix.T[i]\n",
    "    y = np.array([y_classes[i] for i in y_train])\n",
    "    clf.fit(X, y)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_true = np.array([y_classes[i] for i in y_test])\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    true_mask = (y_pred == y_true)\n",
    "    confusion_list = np.array([np.sum(true_mask*(y_test==i))/np.sum(y_test==i) for i in range(l)])\n",
    "    dich_classifiers.append({'model': clf, 'accuracy': accuracy, 'f1': f1, 'confusion_list': confusion_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_codeword(x, dich_classifiers):\n",
    "    codeword = []\n",
    "    for dich in dich_classifiers:\n",
    "        clf = dich['model']\n",
    "        codeword.append(clf.predict(x.reshape(1, -1)))\n",
    "    return np.array(codeword).flatten()\n",
    "\n",
    "def hamming(arr1, arr2, scores=None):\n",
    "#     print(arr1, arr2, scores)\n",
    "    if scores is None:\n",
    "        return (arr1 != arr2).sum()\n",
    "    return ((arr1 != arr2)*scores).sum() + ((arr1 == arr2)*(1-scores)).sum()\n",
    "    \n",
    "def predict_class(x, dich_classifiers, code_matrix, score_type=None, verbose=False):\n",
    "    codeword = predict_codeword(x, dich_classifiers)\n",
    "    if not score_type:\n",
    "        hammings = np.array([hamming(codeword, class_code) for class_code in code_matrix])\n",
    "    else:\n",
    "        scores = np.array([d[score_type] for d in dich_classifiers])\n",
    "        if score_type == 'confusion_list':\n",
    "            # ПРОВЕРИТЬ ВЕРНО ЛИ ФОРМИРУЮТСЯ ОЦЕНКИ ТУТ\n",
    "            hammings = np.array([hamming(codeword, class_code, scores.T[i]) \\\n",
    "                                 for i, class_code in enumerate(code_matrix)])\n",
    "        else:\n",
    "            hammings = np.array([hamming(codeword, class_code, scores) for class_code in code_matrix])\n",
    "    if verbose:\n",
    "        print(hammings)\n",
    "    indices = np.where(hammings == hammings.min())\n",
    "    return np.random.choice(indices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9057239057239057"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = [predict_class(x, dich_classifiers, code_matrix) for x in X_test]\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9107744107744108"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = [predict_class(x, dich_classifiers, code_matrix, 'accuracy') for x in X_test]\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9124579124579124"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = [predict_class(x, dich_classifiers, code_matrix, 'f1') for x in X_test]\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9158249158249159"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = [predict_class(x, dich_classifiers, code_matrix, 'confusion_list') for x in X_test]\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(preds, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сравнения весов (без отбора дихотомий)\n",
    "Сравним разные классификации (хемминг, точность, ф-мера, обучающие данные)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Оптимизация\n",
    "Создаем вектор x1, ... , xN, y (размер N+1)  \n",
    "Далее https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.linprog.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.zeros(N+1)\n",
    "c[-1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# размер A Nx (l*(l-1)/2)\n",
    "A_ub = []\n",
    "b_ub = np.zeros(l*(l-1)//2)\n",
    "\n",
    "for nu in range(l):\n",
    "    for mu in range(nu+1, l):\n",
    "        A_arr = []\n",
    "        for j in range(N):\n",
    "            A_arr.append(-np.abs(code_matrix[nu][j] - code_matrix[mu][j]))\n",
    "        A_arr.append(1)\n",
    "        A_ub.append(A_arr)\n",
    "        \n",
    "A_ub = np.array(A_ub)\n",
    "A_ub = np.vstack([A_ub, -np.eye(N+1)[:-1]]) # x_i >= 0\n",
    "b_ub = np.append(b_ub, np.zeros(N))\n",
    "# or\n",
    "# bounds = np.zeros((N+1, 2))\n",
    "# bounds[:,0] = None\n",
    "# bounds[-1] = None\n",
    "# bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_eq = np.ones(N+1).reshape((1, -1))\n",
    "A_eq[0][-1] = 0\n",
    "b_eq = np.array(N).reshape((-1))\n",
    "A_eq, b_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linprog\n",
    "opt_result = linprog(c, A_ub, b_ub, A_eq, b_eq, options={'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_result['x']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Конструируем модельную задачу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "cluster_objects = 100\n",
    "num_clusters = 5\n",
    "\n",
    "mean = np.zeros(2)\n",
    "cov = np.eye(2) * 0.07\n",
    "X = []\n",
    "\n",
    "y = np.zeros(num_clusters**2*cluster_objects)\n",
    "\n",
    "for i in np.linspace(0, num_clusters-1, num_clusters):\n",
    "    for j in np.linspace(0, num_clusters-1, num_clusters):\n",
    "        mean = np.array([i, j])\n",
    "        X_cluster = np.random.multivariate_normal(mean, cov, cluster_objects)\n",
    "        X.append(X_cluster)\n",
    "X = np.vstack(X)\n",
    "scatter(X[:,0], X[:,1], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# объединяем классы\n",
    "classes_in_cluster = 5\n",
    "\n",
    "order = np.array(range(num_clusters**2))\n",
    "np.random.shuffle(order)\n",
    "splits = np.split(order, 5)\n",
    "for i, split in enumerate(splits):\n",
    "    for item in split:\n",
    "        y[item*cluster_objects:(item+1)*cluster_objects] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)\n",
    "plot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(8, 8)\n",
    "scatter(X[:,0], X[:,1], c=y, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# модельная задача на 12 классов\n",
    "colors = []\n",
    "cs = []\n",
    "\n",
    "# np.random.seed(100)\n",
    "cluster_objects = 100\n",
    "num_clusters = 5\n",
    "\n",
    "mean = np.zeros(2)\n",
    "cov = np.eye(2) * 0.07\n",
    "X = []\n",
    "\n",
    "y = np.zeros(num_clusters**2*cluster_objects)\n",
    "\n",
    "for i in np.linspace(0, 4-1, 4):\n",
    "    for j in np.linspace(0, 5-1, 5):\n",
    "        c = np.random.randint(0, 12)\n",
    "        mean = np.array([i, j])\n",
    "        X_cluster = np.random.multivariate_normal(mean, cov, cluster_objects)\n",
    "        X.append(X_cluster)\n",
    "        colors += [c]*cluster_objects\n",
    "        cs.append(c)\n",
    "X = np.vstack(X)\n",
    "print(cs)\n",
    "scatter(X[:,0], X[:,1], c=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "# Load a multi-label dataset\n",
    "yeast = fetch_mldata('yeast')\n",
    "X = yeast['data']\n",
    "Y = yeast['target'].transpose().toarray()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yeast['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../yeast.data.txt', sep=';', header=None)\n",
    "X = df.values[:,1:-1]\n",
    "y = pd.factorize(df[9])[0]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(tsne_results[:,0], tsne_results[:,1], c=y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
