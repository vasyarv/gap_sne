{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(132)\n",
    "from functools import lru_cache\n",
    "\n",
    "import sys\n",
    "\n",
    "CODE_PATH = '../code'\n",
    "\n",
    "sys.path.append(CODE_PATH)\n",
    "import functions\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.datasets import load_iris, load_boston, load_breast_cancer, load_wine, load_digits\n",
    "from scipy.optimize import minimize\n",
    "from tqdm import tqdm\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1005, 64) (360, 64) (432, 64)\n"
     ]
    }
   ],
   "source": [
    "# dataset = load_breast_cancer()\n",
    "dataset = load_digits()\n",
    "df = pd.DataFrame(dataset['data'])\n",
    "target = dataset['target']\n",
    "# df = (df - df.mean())/(df.max() - df.min())\n",
    "# df0 = df.copy()\n",
    "# print(df.shape)\n",
    "# print(target)\n",
    "df.head()\n",
    "\n",
    "# train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(df.values, target, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.values, target, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_test.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучаем классификаторы и строим матрицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding dich: 100%|██████████| 50/50 [00:00<00:00, 18712.88it/s]\n",
      "Training dich classifiers: 100%|██████████| 50/50 [00:01<00:00, 39.08it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "l = np.unique(target).size\n",
    "N = 50 # кол-во дихотомий\n",
    "code_matrix = functions.make_random_dichs(l, N)\n",
    "\n",
    "dich_classifiers = functions.train_dichs(code_matrix, X_train, y_train, \n",
    "                                         X_test, y_test, LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "Adding dich:   0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Adding dich: 100%|██████████| 30/30 [00:00<00:00, 19831.22it/s]\u001b[A\n",
      "Training dich classifiers:   0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Training dich classifiers:  10%|█         | 3/30 [00:00<00:00, 29.26it/s]\u001b[A\n",
      "Training dich classifiers:  23%|██▎       | 7/30 [00:00<00:00, 30.70it/s]\u001b[A\n",
      "Training dich classifiers:  40%|████      | 12/30 [00:00<00:00, 33.12it/s]\u001b[A\n",
      "Training dich classifiers:  53%|█████▎    | 16/30 [00:00<00:00, 34.16it/s]\u001b[A\n",
      "Training dich classifiers:  67%|██████▋   | 20/30 [00:00<00:00, 35.03it/s]\u001b[A\n",
      "Training dich classifiers:  83%|████████▎ | 25/30 [00:00<00:00, 36.40it/s]\u001b[A\n",
      "Training dich classifiers: 100%|██████████| 30/30 [00:00<00:00, 37.69it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:06<00:55,  6.17s/it]\n",
      "Adding dich:   0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Adding dich: 100%|██████████| 30/30 [00:00<00:00, 29704.70it/s]\u001b[A\n",
      "Training dich classifiers:   0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Training dich classifiers:  13%|█▎        | 4/30 [00:00<00:00, 39.02it/s]\u001b[A\n",
      "Training dich classifiers:  30%|███       | 9/30 [00:00<00:00, 39.30it/s]\u001b[A\n",
      "Training dich classifiers:  47%|████▋     | 14/30 [00:00<00:00, 39.84it/s]\u001b[A\n",
      "Training dich classifiers:  63%|██████▎   | 19/30 [00:00<00:00, 41.27it/s]\u001b[A\n",
      "Training dich classifiers:  80%|████████  | 24/30 [00:00<00:00, 41.12it/s]\u001b[A\n",
      "Training dich classifiers:  93%|█████████▎| 28/30 [00:00<00:00, 40.66it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:12<00:49,  6.13s/it]/30 [00:00<00:00, 41.11it/s]\u001b[A\n",
      "Adding dich:   0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Adding dich: 100%|██████████| 30/30 [00:00<00:00, 32674.40it/s]\u001b[A\n",
      "Training dich classifiers:   0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Training dich classifiers:  17%|█▋        | 5/30 [00:00<00:00, 48.64it/s]\u001b[A\n",
      "Training dich classifiers:  30%|███       | 9/30 [00:00<00:00, 45.63it/s]\u001b[A\n",
      "Training dich classifiers:  47%|████▋     | 14/30 [00:00<00:00, 46.74it/s]\u001b[A\n",
      "Training dich classifiers:  63%|██████▎   | 19/30 [00:00<00:00, 44.90it/s]\u001b[A\n",
      "Training dich classifiers:  77%|███████▋  | 23/30 [00:00<00:00, 41.88it/s]\u001b[A\n",
      "Training dich classifiers:  90%|█████████ | 27/30 [00:00<00:00, 40.73it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:18<00:42,  6.12s/it]/30 [00:00<00:00, 42.40it/s]\u001b[A\n",
      "Adding dich:   0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Adding dich: 100%|██████████| 30/30 [00:00<00:00, 32768.00it/s]\u001b[A\n",
      "Training dich classifiers:   0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Training dich classifiers:  13%|█▎        | 4/30 [00:00<00:00, 35.04it/s]\u001b[A\n",
      "Training dich classifiers:  27%|██▋       | 8/30 [00:00<00:00, 36.20it/s]\u001b[A\n",
      "Training dich classifiers:  43%|████▎     | 13/30 [00:00<00:00, 39.21it/s]\u001b[A\n",
      "Training dich classifiers:  57%|█████▋    | 17/30 [00:00<00:00, 38.15it/s]\u001b[A\n",
      "Training dich classifiers:  73%|███████▎  | 22/30 [00:00<00:00, 39.94it/s]\u001b[A\n",
      "Training dich classifiers:  90%|█████████ | 27/30 [00:00<00:00, 39.90it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:24<00:36,  6.10s/it]/30 [00:00<00:00, 40.07it/s]\u001b[A\n",
      "Adding dich:   0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Adding dich: 100%|██████████| 30/30 [00:00<00:00, 30578.16it/s]\u001b[A\n",
      "Training dich classifiers:   0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Training dich classifiers:  17%|█▋        | 5/30 [00:00<00:00, 42.10it/s]\u001b[A\n",
      "Training dich classifiers:  30%|███       | 9/30 [00:00<00:00, 40.96it/s]\u001b[A\n",
      "Training dich classifiers:  43%|████▎     | 13/30 [00:00<00:00, 39.96it/s]\u001b[A\n",
      "Training dich classifiers:  60%|██████    | 18/30 [00:00<00:00, 40.17it/s]\u001b[A\n",
      "Training dich classifiers:  77%|███████▋  | 23/30 [00:00<00:00, 40.75it/s]\u001b[A\n",
      "Training dich classifiers:  90%|█████████ | 27/30 [00:00<00:00, 39.20it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:30<00:30,  6.10s/it]/30 [00:00<00:00, 40.04it/s]\u001b[A\n",
      "Adding dich:   0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Adding dich: 100%|██████████| 30/30 [00:00<00:00, 30504.03it/s]\u001b[A\n",
      "Training dich classifiers:   0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Training dich classifiers:  17%|█▋        | 5/30 [00:00<00:00, 41.71it/s]\u001b[A\n",
      "Training dich classifiers:  30%|███       | 9/30 [00:00<00:00, 40.90it/s]\u001b[A\n",
      "Training dich classifiers:  47%|████▋     | 14/30 [00:00<00:00, 41.18it/s]\u001b[A\n",
      "Training dich classifiers:  63%|██████▎   | 19/30 [00:00<00:00, 42.42it/s]\u001b[A\n",
      "Training dich classifiers:  77%|███████▋  | 23/30 [00:00<00:00, 41.05it/s]\u001b[A\n",
      "Training dich classifiers:  90%|█████████ | 27/30 [00:00<00:00, 40.20it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:36<00:24,  6.12s/it]/30 [00:00<00:00, 40.38it/s]\u001b[A\n",
      "Adding dich:   0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Adding dich: 100%|██████████| 30/30 [00:00<00:00, 30437.62it/s]\u001b[A\n",
      "Training dich classifiers:   0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Training dich classifiers:  13%|█▎        | 4/30 [00:00<00:00, 37.71it/s]\u001b[A\n",
      "Training dich classifiers:  30%|███       | 9/30 [00:00<00:00, 38.83it/s]\u001b[A\n",
      "Training dich classifiers:  47%|████▋     | 14/30 [00:00<00:00, 39.83it/s]\u001b[A\n",
      "Training dich classifiers:  67%|██████▋   | 20/30 [00:00<00:00, 41.94it/s]\u001b[A\n",
      "Training dich classifiers:  83%|████████▎ | 25/30 [00:00<00:00, 42.51it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:42<00:18,  6.09s/it]/30 [00:00<00:00, 44.32it/s]\u001b[A\n",
      "Adding dich:   0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Adding dich: 100%|██████████| 30/30 [00:00<00:00, 32321.89it/s]\u001b[A\n",
      "Training dich classifiers:   0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Training dich classifiers:  20%|██        | 6/30 [00:00<00:00, 50.07it/s]\u001b[A\n",
      "Training dich classifiers:  37%|███▋      | 11/30 [00:00<00:00, 50.03it/s]\u001b[A\n",
      "Training dich classifiers:  50%|█████     | 15/30 [00:00<00:00, 44.85it/s]\u001b[A\n",
      "Training dich classifiers:  67%|██████▋   | 20/30 [00:00<00:00, 43.70it/s]\u001b[A\n",
      "Training dich classifiers:  83%|████████▎ | 25/30 [00:00<00:00, 44.44it/s]\u001b[A\n",
      "Training dich classifiers: 100%|██████████| 30/30 [00:00<00:00, 43.02it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:48<00:12,  6.08s/it]\n",
      "Adding dich:   0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Adding dich: 100%|██████████| 30/30 [00:00<00:00, 32363.46it/s]\u001b[A\n",
      "Training dich classifiers:   0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Training dich classifiers:  17%|█▋        | 5/30 [00:00<00:00, 41.33it/s]\u001b[A\n",
      "Training dich classifiers:  30%|███       | 9/30 [00:00<00:00, 40.90it/s]\u001b[A\n",
      "Training dich classifiers:  43%|████▎     | 13/30 [00:00<00:00, 40.12it/s]\u001b[A\n",
      "Training dich classifiers:  60%|██████    | 18/30 [00:00<00:00, 40.48it/s]\u001b[A\n",
      "Training dich classifiers:  77%|███████▋  | 23/30 [00:00<00:00, 41.02it/s]\u001b[A\n",
      "Training dich classifiers:  90%|█████████ | 27/30 [00:00<00:00, 40.10it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:54<00:06,  6.06s/it]/30 [00:00<00:00, 40.30it/s]\u001b[A\n",
      "Adding dich:   0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Adding dich: 100%|██████████| 30/30 [00:00<00:00, 31076.59it/s]\u001b[A\n",
      "Training dich classifiers:   0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Training dich classifiers:  17%|█▋        | 5/30 [00:00<00:00, 44.67it/s]\u001b[A\n",
      "Training dich classifiers:  30%|███       | 9/30 [00:00<00:00, 42.81it/s]\u001b[A\n",
      "Training dich classifiers:  47%|████▋     | 14/30 [00:00<00:00, 43.94it/s]\u001b[A\n",
      "Training dich classifiers:  63%|██████▎   | 19/30 [00:00<00:00, 42.51it/s]\u001b[A\n",
      "Training dich classifiers:  80%|████████  | 24/30 [00:00<00:00, 41.84it/s]\u001b[A\n",
      "Training dich classifiers:  97%|█████████▋| 29/30 [00:00<00:00, 43.15it/s]\u001b[A\n",
      "100%|██████████| 10/10 [01:00<00:00,  6.04s/it]30 [00:00<00:00, 42.60it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "attempts_data = []\n",
    "N_attempts = 10\n",
    "N = 30 # кол-во дихотомий\n",
    "wtypes = [None, 'accuracy', 'f1', 'confusion_list']\n",
    "for i in tqdm(range(N_attempts)):\n",
    "    accs = []\n",
    "    code_matrix = functions.make_random_dichs(l, N)\n",
    "    dich_classifiers = functions.train_dichs(code_matrix, X_train, y_train, \n",
    "                                             X_test, y_test, LogisticRegression)\n",
    "    for score_type in wtypes:\n",
    "        for weight_type in wtypes:\n",
    "            preds = functions.predict_all(X_val, dich_classifiers, code_matrix, score_type, weight_type)\n",
    "            acc = accuracy_score(preds, y_val)\n",
    "            accs.append(acc)\n",
    "    attempts_data.append(accs)\n",
    "#             print(score_type, weight_type, accuracy_score(preds, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sNone_wNone</th>\n",
       "      <th>sNone_waccuracy</th>\n",
       "      <th>sNone_wf1</th>\n",
       "      <th>sNone_wconfusion_list</th>\n",
       "      <th>saccuracy_wNone</th>\n",
       "      <th>saccuracy_waccuracy</th>\n",
       "      <th>saccuracy_wf1</th>\n",
       "      <th>saccuracy_wconfusion_list</th>\n",
       "      <th>sf1_wNone</th>\n",
       "      <th>sf1_waccuracy</th>\n",
       "      <th>sf1_wf1</th>\n",
       "      <th>sf1_wconfusion_list</th>\n",
       "      <th>sconfusion_list_wNone</th>\n",
       "      <th>sconfusion_list_waccuracy</th>\n",
       "      <th>sconfusion_list_wf1</th>\n",
       "      <th>sconfusion_list_wconfusion_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.900463</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.912037</td>\n",
       "      <td>0.840278</td>\n",
       "      <td>0.840278</td>\n",
       "      <td>0.840278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.905093</td>\n",
       "      <td>0.909722</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.905093</td>\n",
       "      <td>0.905093</td>\n",
       "      <td>0.905093</td>\n",
       "      <td>0.905093</td>\n",
       "      <td>0.909722</td>\n",
       "      <td>0.868056</td>\n",
       "      <td>0.868056</td>\n",
       "      <td>0.868056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.900463</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.900463</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.835648</td>\n",
       "      <td>0.835648</td>\n",
       "      <td>0.835648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.900463</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.905093</td>\n",
       "      <td>0.905093</td>\n",
       "      <td>0.905093</td>\n",
       "      <td>0.905093</td>\n",
       "      <td>0.905093</td>\n",
       "      <td>0.905093</td>\n",
       "      <td>0.905093</td>\n",
       "      <td>0.905093</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.870370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.891204</td>\n",
       "      <td>0.891204</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.905093</td>\n",
       "      <td>0.826389</td>\n",
       "      <td>0.826389</td>\n",
       "      <td>0.826389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.881944</td>\n",
       "      <td>0.886574</td>\n",
       "      <td>0.886574</td>\n",
       "      <td>0.884259</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.891204</td>\n",
       "      <td>0.891204</td>\n",
       "      <td>0.891204</td>\n",
       "      <td>0.891204</td>\n",
       "      <td>0.891204</td>\n",
       "      <td>0.798611</td>\n",
       "      <td>0.798611</td>\n",
       "      <td>0.798611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.872685</td>\n",
       "      <td>0.868056</td>\n",
       "      <td>0.868056</td>\n",
       "      <td>0.872685</td>\n",
       "      <td>0.872685</td>\n",
       "      <td>0.872685</td>\n",
       "      <td>0.872685</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.886574</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.740741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.900463</td>\n",
       "      <td>0.891204</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.900463</td>\n",
       "      <td>0.900463</td>\n",
       "      <td>0.900463</td>\n",
       "      <td>0.900463</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.805556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.900463</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.831019</td>\n",
       "      <td>0.831019</td>\n",
       "      <td>0.831019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.900463</td>\n",
       "      <td>0.905093</td>\n",
       "      <td>0.905093</td>\n",
       "      <td>0.905093</td>\n",
       "      <td>0.905093</td>\n",
       "      <td>0.905093</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.796296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sNone_wNone  sNone_waccuracy  sNone_wf1  sNone_wconfusion_list  \\\n",
       "0     0.900463         0.898148   0.898148               0.902778   \n",
       "1     0.907407         0.907407   0.905093               0.909722   \n",
       "2     0.893519         0.900463   0.895833               0.900463   \n",
       "3     0.895833         0.888889   0.900463               0.895833   \n",
       "4     0.893519         0.891204   0.891204               0.893519   \n",
       "5     0.881944         0.886574   0.886574               0.884259   \n",
       "6     0.861111         0.872685   0.868056               0.868056   \n",
       "7     0.893519         0.900463   0.891204               0.902778   \n",
       "8     0.893519         0.898148   0.893519               0.900463   \n",
       "9     0.902778         0.902778   0.900463               0.905093   \n",
       "\n",
       "   saccuracy_wNone  saccuracy_waccuracy  saccuracy_wf1  \\\n",
       "0         0.902778             0.902778       0.902778   \n",
       "1         0.907407             0.907407       0.907407   \n",
       "2         0.893519             0.893519       0.893519   \n",
       "3         0.905093             0.905093       0.905093   \n",
       "4         0.895833             0.895833       0.895833   \n",
       "5         0.893519             0.893519       0.893519   \n",
       "6         0.872685             0.872685       0.872685   \n",
       "7         0.898148             0.898148       0.898148   \n",
       "8         0.898148             0.898148       0.898148   \n",
       "9         0.905093             0.905093       0.905093   \n",
       "\n",
       "   saccuracy_wconfusion_list  sf1_wNone  sf1_waccuracy   sf1_wf1  \\\n",
       "0                   0.902778   0.902778       0.902778  0.902778   \n",
       "1                   0.907407   0.905093       0.905093  0.905093   \n",
       "2                   0.893519   0.893519       0.893519  0.893519   \n",
       "3                   0.905093   0.905093       0.905093  0.905093   \n",
       "4                   0.895833   0.898148       0.898148  0.898148   \n",
       "5                   0.893519   0.891204       0.891204  0.891204   \n",
       "6                   0.872685   0.870370       0.870370  0.870370   \n",
       "7                   0.898148   0.900463       0.900463  0.900463   \n",
       "8                   0.898148   0.893519       0.893519  0.893519   \n",
       "9                   0.905093   0.902778       0.902778  0.902778   \n",
       "\n",
       "   sf1_wconfusion_list  sconfusion_list_wNone  sconfusion_list_waccuracy  \\\n",
       "0             0.902778               0.912037                   0.840278   \n",
       "1             0.905093               0.909722                   0.868056   \n",
       "2             0.893519               0.893519                   0.835648   \n",
       "3             0.905093               0.895833                   0.870370   \n",
       "4             0.898148               0.905093                   0.826389   \n",
       "5             0.891204               0.891204                   0.798611   \n",
       "6             0.870370               0.886574                   0.740741   \n",
       "7             0.900463               0.902778                   0.805556   \n",
       "8             0.893519               0.893519                   0.831019   \n",
       "9             0.902778               0.902778                   0.796296   \n",
       "\n",
       "   sconfusion_list_wf1  sconfusion_list_wconfusion_list  \n",
       "0             0.840278                         0.840278  \n",
       "1             0.868056                         0.868056  \n",
       "2             0.835648                         0.835648  \n",
       "3             0.870370                         0.870370  \n",
       "4             0.826389                         0.826389  \n",
       "5             0.798611                         0.798611  \n",
       "6             0.740741                         0.740741  \n",
       "7             0.805556                         0.805556  \n",
       "8             0.831019                         0.831019  \n",
       "9             0.796296                         0.796296  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_attempts = pd.DataFrame(attempts_data)\n",
    "df_attempts.columns = ['s{}_w{}'.format(i1, i2) for i1 in wtypes for i2 in wtypes]\n",
    "df_attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sNone_wNone</th>\n",
       "      <th>sNone_waccuracy</th>\n",
       "      <th>sNone_wf1</th>\n",
       "      <th>sNone_wconfusion_list</th>\n",
       "      <th>saccuracy_wNone</th>\n",
       "      <th>saccuracy_waccuracy</th>\n",
       "      <th>saccuracy_wf1</th>\n",
       "      <th>saccuracy_wconfusion_list</th>\n",
       "      <th>sf1_wNone</th>\n",
       "      <th>sf1_waccuracy</th>\n",
       "      <th>sf1_wf1</th>\n",
       "      <th>sf1_wconfusion_list</th>\n",
       "      <th>sconfusion_list_wNone</th>\n",
       "      <th>sconfusion_list_waccuracy</th>\n",
       "      <th>sconfusion_list_wf1</th>\n",
       "      <th>sconfusion_list_wconfusion_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.892361</td>\n",
       "      <td>0.894676</td>\n",
       "      <td>0.893056</td>\n",
       "      <td>0.896296</td>\n",
       "      <td>0.897222</td>\n",
       "      <td>0.897222</td>\n",
       "      <td>0.897222</td>\n",
       "      <td>0.897222</td>\n",
       "      <td>0.896296</td>\n",
       "      <td>0.896296</td>\n",
       "      <td>0.896296</td>\n",
       "      <td>0.896296</td>\n",
       "      <td>0.899306</td>\n",
       "      <td>0.821296</td>\n",
       "      <td>0.821296</td>\n",
       "      <td>0.821296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.012923</td>\n",
       "      <td>0.010075</td>\n",
       "      <td>0.010341</td>\n",
       "      <td>0.012141</td>\n",
       "      <td>0.009953</td>\n",
       "      <td>0.009953</td>\n",
       "      <td>0.009953</td>\n",
       "      <td>0.009953</td>\n",
       "      <td>0.010398</td>\n",
       "      <td>0.010398</td>\n",
       "      <td>0.010398</td>\n",
       "      <td>0.010398</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>0.038236</td>\n",
       "      <td>0.038236</td>\n",
       "      <td>0.038236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.872685</td>\n",
       "      <td>0.868056</td>\n",
       "      <td>0.868056</td>\n",
       "      <td>0.872685</td>\n",
       "      <td>0.872685</td>\n",
       "      <td>0.872685</td>\n",
       "      <td>0.872685</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.886574</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.740741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.889468</td>\n",
       "      <td>0.891204</td>\n",
       "      <td>0.894097</td>\n",
       "      <td>0.894097</td>\n",
       "      <td>0.894097</td>\n",
       "      <td>0.894097</td>\n",
       "      <td>0.894097</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.800347</td>\n",
       "      <td>0.800347</td>\n",
       "      <td>0.800347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.894676</td>\n",
       "      <td>0.900463</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.899306</td>\n",
       "      <td>0.899306</td>\n",
       "      <td>0.899306</td>\n",
       "      <td>0.899306</td>\n",
       "      <td>0.899306</td>\n",
       "      <td>0.828704</td>\n",
       "      <td>0.828704</td>\n",
       "      <td>0.828704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.899306</td>\n",
       "      <td>0.900463</td>\n",
       "      <td>0.899884</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.904514</td>\n",
       "      <td>0.904514</td>\n",
       "      <td>0.904514</td>\n",
       "      <td>0.904514</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.904514</td>\n",
       "      <td>0.839120</td>\n",
       "      <td>0.839120</td>\n",
       "      <td>0.839120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.905093</td>\n",
       "      <td>0.909722</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.905093</td>\n",
       "      <td>0.905093</td>\n",
       "      <td>0.905093</td>\n",
       "      <td>0.905093</td>\n",
       "      <td>0.912037</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.870370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sNone_wNone  sNone_waccuracy  sNone_wf1  sNone_wconfusion_list  \\\n",
       "count    10.000000        10.000000  10.000000              10.000000   \n",
       "mean      0.892361         0.894676   0.893056               0.896296   \n",
       "std       0.012923         0.010075   0.010341               0.012141   \n",
       "min       0.861111         0.872685   0.868056               0.868056   \n",
       "25%       0.893519         0.889468   0.891204               0.894097   \n",
       "50%       0.893519         0.898148   0.894676               0.900463   \n",
       "75%       0.899306         0.900463   0.899884               0.902778   \n",
       "max       0.907407         0.907407   0.905093               0.909722   \n",
       "\n",
       "       saccuracy_wNone  saccuracy_waccuracy  saccuracy_wf1  \\\n",
       "count        10.000000            10.000000      10.000000   \n",
       "mean          0.897222             0.897222       0.897222   \n",
       "std           0.009953             0.009953       0.009953   \n",
       "min           0.872685             0.872685       0.872685   \n",
       "25%           0.894097             0.894097       0.894097   \n",
       "50%           0.898148             0.898148       0.898148   \n",
       "75%           0.904514             0.904514       0.904514   \n",
       "max           0.907407             0.907407       0.907407   \n",
       "\n",
       "       saccuracy_wconfusion_list  sf1_wNone  sf1_waccuracy    sf1_wf1  \\\n",
       "count                  10.000000  10.000000      10.000000  10.000000   \n",
       "mean                    0.897222   0.896296       0.896296   0.896296   \n",
       "std                     0.009953   0.010398       0.010398   0.010398   \n",
       "min                     0.872685   0.870370       0.870370   0.870370   \n",
       "25%                     0.894097   0.893519       0.893519   0.893519   \n",
       "50%                     0.898148   0.899306       0.899306   0.899306   \n",
       "75%                     0.904514   0.902778       0.902778   0.902778   \n",
       "max                     0.907407   0.905093       0.905093   0.905093   \n",
       "\n",
       "       sf1_wconfusion_list  sconfusion_list_wNone  sconfusion_list_waccuracy  \\\n",
       "count            10.000000              10.000000                  10.000000   \n",
       "mean              0.896296               0.899306                   0.821296   \n",
       "std               0.010398               0.008400                   0.038236   \n",
       "min               0.870370               0.886574                   0.740741   \n",
       "25%               0.893519               0.893519                   0.800347   \n",
       "50%               0.899306               0.899306                   0.828704   \n",
       "75%               0.902778               0.904514                   0.839120   \n",
       "max               0.905093               0.912037                   0.870370   \n",
       "\n",
       "       sconfusion_list_wf1  sconfusion_list_wconfusion_list  \n",
       "count            10.000000                        10.000000  \n",
       "mean              0.821296                         0.821296  \n",
       "std               0.038236                         0.038236  \n",
       "min               0.740741                         0.740741  \n",
       "25%               0.800347                         0.800347  \n",
       "50%               0.828704                         0.828704  \n",
       "75%               0.839120                         0.839120  \n",
       "max               0.870370                         0.870370  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_attempts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attempts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Конструируем модельную задачу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "cluster_objects = 100\n",
    "num_clusters = 5\n",
    "\n",
    "mean = np.zeros(2)\n",
    "cov = np.eye(2) * 0.07\n",
    "X = []\n",
    "\n",
    "y = np.zeros(num_clusters**2*cluster_objects)\n",
    "\n",
    "for i in np.linspace(0, num_clusters-1, num_clusters):\n",
    "    for j in np.linspace(0, num_clusters-1, num_clusters):\n",
    "        mean = np.array([i, j])\n",
    "        X_cluster = np.random.multivariate_normal(mean, cov, cluster_objects)\n",
    "        X.append(X_cluster)\n",
    "X = np.vstack(X)\n",
    "scatter(X[:,0], X[:,1], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# объединяем классы\n",
    "classes_in_cluster = 5\n",
    "\n",
    "order = np.array(range(num_clusters**2))\n",
    "np.random.shuffle(order)\n",
    "splits = np.split(order, 5)\n",
    "for i, split in enumerate(splits):\n",
    "    for item in split:\n",
    "        y[item*cluster_objects:(item+1)*cluster_objects] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)\n",
    "plot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(8, 8)\n",
    "scatter(X[:,0], X[:,1], c=y, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# модельная задача на 12 классов\n",
    "colors = []\n",
    "cs = []\n",
    "\n",
    "# np.random.seed(100)\n",
    "cluster_objects = 100\n",
    "num_clusters = 5\n",
    "\n",
    "mean = np.zeros(2)\n",
    "cov = np.eye(2) * 0.07\n",
    "X = []\n",
    "\n",
    "y = np.zeros(num_clusters**2*cluster_objects)\n",
    "\n",
    "for i in np.linspace(0, 4-1, 4):\n",
    "    for j in np.linspace(0, 5-1, 5):\n",
    "        c = np.random.randint(0, 12)\n",
    "        mean = np.array([i, j])\n",
    "        X_cluster = np.random.multivariate_normal(mean, cov, cluster_objects)\n",
    "        X.append(X_cluster)\n",
    "        colors += [c]*cluster_objects\n",
    "        cs.append(c)\n",
    "X = np.vstack(X)\n",
    "print(cs)\n",
    "scatter(X[:,0], X[:,1], c=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "# Load a multi-label dataset\n",
    "yeast = fetch_mldata('yeast')\n",
    "X = yeast['data']\n",
    "Y = yeast['target'].transpose().toarray()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yeast['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../yeast.data.txt', sep=';', header=None)\n",
    "X = df.values[:,1:-1]\n",
    "y = pd.factorize(df[9])[0]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(tsne_results[:,0], tsne_results[:,1], c=y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
