{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(132)\n",
    "from functools import lru_cache\n",
    "\n",
    "import sys\n",
    "\n",
    "CODE_PATH = '../code'\n",
    "\n",
    "sys.path.append(CODE_PATH)\n",
    "import functions\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.datasets import load_iris, load_boston, load_breast_cancer, load_wine, load_digits\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm import tqdm\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1005, 64) (360, 64) (432, 64)\n"
     ]
    }
   ],
   "source": [
    "# dataset = load_breast_cancer()\n",
    "dataset = load_digits()\n",
    "df = pd.DataFrame(dataset['data'])\n",
    "target = dataset['target']\n",
    "# df = (df - df.mean())/(df.max() - df.min())\n",
    "# df0 = df.copy()\n",
    "# print(df.shape)\n",
    "# print(target)\n",
    "df.head()\n",
    "\n",
    "# train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(df.values, target, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.values, target, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_test.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучаем классификаторы и строим матрицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding dich: 100%|██████████| 50/50 [00:00<00:00, 15660.91it/s]\n",
      "Training dich classifiers: 100%|██████████| 50/50 [00:01<00:00, 39.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# типа образец\n",
    "l = np.unique(target).size\n",
    "N = 50 # кол-во дихотомий\n",
    "code_matrix = functions.make_random_dichs(l, N)\n",
    "\n",
    "dich_classifiers = functions.train_dichs(code_matrix, X_train, y_train, \n",
    "                                         X_test, y_test, LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classes = code_matrix.T[i]\n",
    "y = np.array([y_classes[i] for i in y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверка кластерных индексов\n",
    "dich1 = code_matrix.T[0]\n",
    "dich2 = dich1.copy()\n",
    "dich2[0] = 1 - dich2[0]\n",
    "y1 = np.array([random_dich[i] for i in y_train])\n",
    "y2 = np.array([random_dich[i] for i in y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "functions.cluster_score(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attempts_data = []\n",
    "N_attempts = 10\n",
    "N = 30 # кол-во дихотомий\n",
    "wtypes = [None, 'accuracy', 'f1', 'confusion_list']\n",
    "for i in tqdm(range(N_attempts)):\n",
    "    accs = []\n",
    "    code_matrix = functions.make_random_dichs(l, N)\n",
    "    dich_classifiers = functions.train_dichs(code_matrix, X_train, y_train, \n",
    "                                             X_test, y_test, LogisticRegression)\n",
    "    for score_type in wtypes:\n",
    "        for weight_type in wtypes:\n",
    "            preds = functions.predict_all(X_val, dich_classifiers, code_matrix, score_type, weight_type)\n",
    "            acc = accuracy_score(preds, y_val)\n",
    "            accs.append(acc)\n",
    "    attempts_data.append(accs)\n",
    "#             print(score_type, weight_type, accuracy_score(preds, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_attempts = pd.DataFrame(attempts_data)\n",
    "df_attempts.columns = ['s{}_w{}'.format(i1, i2) for i1 in wtypes for i2 in wtypes]\n",
    "df_attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attempts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1,1,1])\n",
    "np.random.choice(np.flatnonzero(x == x.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Локальный метод оптимизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_dich = None\n",
    "cur_score = score_function(cur_dich, X_train, y_train)\n",
    "next_score = cur_score\n",
    "while True:\n",
    "    next_dich = cur_score.copy()\n",
    "    next_scores = np.zeros(len(cur_dich)) - 1\n",
    "    for i in range(len(cur_dich)):\n",
    "        next_dich = cur_dich.copy()\n",
    "        next_dich[i] = 1 - next_dich[i]\n",
    "        if not functions.does_dich_exist(next_dich): #дихотомия нормальная\n",
    "            next_scores[i] = score_function(next_dich, X_train, y_train)\n",
    "    next_scores = np.array(next_scores)\n",
    "    next_score = next_scores.max(\n",
    "    if next_score <= cur_score: #идем только на повышение, но можно скор сделать поменьше\n",
    "        break\n",
    "    cur_score = next_score\n",
    "    best_index = np.random.choice(np.flatnonzero(next_scores == next_score)) # it is random of the best\n",
    "    cur_dich[best_index] = 1 - cur_dich[best_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Конструируем модельную задачу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "cluster_objects = 100\n",
    "num_clusters = 5\n",
    "\n",
    "mean = np.zeros(2)\n",
    "cov = np.eye(2) * 0.07\n",
    "X = []\n",
    "\n",
    "y = np.zeros(num_clusters**2*cluster_objects)\n",
    "\n",
    "for i in np.linspace(0, num_clusters-1, num_clusters):\n",
    "    for j in np.linspace(0, num_clusters-1, num_clusters):\n",
    "        mean = np.array([i, j])\n",
    "        X_cluster = np.random.multivariate_normal(mean, cov, cluster_objects)\n",
    "        X.append(X_cluster)\n",
    "X = np.vstack(X)\n",
    "scatter(X[:,0], X[:,1], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# объединяем классы\n",
    "classes_in_cluster = 5\n",
    "\n",
    "order = np.array(range(num_clusters**2))\n",
    "np.random.shuffle(order)\n",
    "splits = np.split(order, 5)\n",
    "for i, split in enumerate(splits):\n",
    "    for item in split:\n",
    "        y[item*cluster_objects:(item+1)*cluster_objects] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)\n",
    "plot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(8, 8)\n",
    "scatter(X[:,0], X[:,1], c=y, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# модельная задача на 12 классов\n",
    "colors = []\n",
    "cs = []\n",
    "\n",
    "# np.random.seed(100)\n",
    "cluster_objects = 100\n",
    "num_clusters = 5\n",
    "\n",
    "mean = np.zeros(2)\n",
    "cov = np.eye(2) * 0.07\n",
    "X = []\n",
    "\n",
    "y = np.zeros(num_clusters**2*cluster_objects)\n",
    "\n",
    "for i in np.linspace(0, 4-1, 4):\n",
    "    for j in np.linspace(0, 5-1, 5):\n",
    "        c = np.random.randint(0, 12)\n",
    "        mean = np.array([i, j])\n",
    "        X_cluster = np.random.multivariate_normal(mean, cov, cluster_objects)\n",
    "        X.append(X_cluster)\n",
    "        colors += [c]*cluster_objects\n",
    "        cs.append(c)\n",
    "X = np.vstack(X)\n",
    "print(cs)\n",
    "scatter(X[:,0], X[:,1], c=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "# Load a multi-label dataset\n",
    "yeast = fetch_mldata('yeast')\n",
    "X = yeast['data']\n",
    "Y = yeast['target'].transpose().toarray()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yeast['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../yeast.data.txt', sep=';', header=None)\n",
    "X = df.values[:,1:-1]\n",
    "y = pd.factorize(df[9])[0]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(tsne_results[:,0], tsne_results[:,1], c=y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
